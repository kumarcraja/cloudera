Identified all hosts network ips and configured /etc/hosts as follows

172.31.1.209 node1
172.31.1.208 node2
172.31.1.207 node3
172.31.1.210 node4
172.31.1.211 node5

Also created two custom script sync configuration fie to all nodes, and run commands in all nodes.

custer_fork

[root@ip-172-31-1-209 sbin]# cat cluster_fork 
#!/bin/bash

for node in node2 node3 node4 node5
do
ssh $node $*
done

cluster_scp

#!/bin/bash

for node in node2 node3 node4 node5
do
rsync -rvlogtP $1 $node:$2
done



1) 

vm.swapiness set to 1 in all nodes

1
[root@ip-172-31-1-209 sbin]# ./cluster_fork 'cat /proc/sys/vm/swappiness'
1
1
1
1

2)

Mount attributes of disks in all nodes

[root@ip-172-31-1-209 sbin]# mount | grep xvda
/dev/xvda2 on / type xfs (rw,relatime,seclabel,attr2,inode64,noquota)
[root@ip-172-31-1-209 sbin]# ./cluster_fork 'mount | grep xvda'aa
/dev/xvda2 on / type xfs (rw,relatime,seclabel,attr2,inode64,noquota)
/dev/xvda2 on / type xfs (rw,relatime,seclabel,attr2,inode64,noquota)
/dev/xvda2 on / type xfs (rw,relatime,seclabel,attr2,inode64,noquota)
/dev/xvda2 on / type xfs (rw,relatime,seclabel,attr2,inode64,noquota)
[root@ip-172-31-1-209 sbin]# 


3) 

We are using xfs file system, no reserve space for any non root usercat	

4)

transparent_hugepage disabled
=========================


[root@ip-172-31-1-209 sbin]# cat /sys/kernel/mm/transparent_hugepage/enabled 
always madvise [never]

[root@ip-172-31-1-209 sbin]# ./cluster_fork 'cat /sys/kernel/mm/transparent_hugepage/enabled'
[always] madvise never
[always] madvise never
[always] madvise never
[always] madvise never


5) 

Network interface details

eth0 172.31.1.209 node1
eth0 172.31.1.208 node2
eth0 172.31.1.207 node3
eth0 172.31.1.210 node4
eth0 172.31.1.211 node5

6) 

[root@ip-172-31-1-209 sbin]# cat /etc/hosts
127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4
::1         localhost localhost.localdomain localhost6 localhost6.localdomain6


172.31.1.209 ip-172-31-1-209.us-west-2.compute.internal
172.31.1.208 ip-172-31-1-208.us-west-2.compute.internal
172.31.1.207 ip-172-31-1-207.us-west-2.compute.internal
172.31.1.210 ip-172-31-1-210.us-west-2.compute.internal
172.31.1.211 ip-172-31-1-211.us-west-2.compute.internal
[root@ip-172-31-1-209 sbin]# cat /etc/resolv.conf 
# Generated by NetworkManager
search us-west-2.compute.internal
nameserver 172.31.0.2
[root@ip-172-31-1-209 sbin]# getent hosts ip-172-31-1-209.us-west-2.compute.internal
172.31.1.209    ip-172-31-1-209.us-west-2.compute.internal
[root@ip-172-31-1-209 sbin]# getent hosts 172.31.1.209
172.31.1.209    ip-172-31-1-209.us-west-2.compute.internal
[root@ip-172-31-1-209 sbin]# nslookup ip-172-31-1-209.us-west-2.compute.internal
Server:		172.31.0.2
Address:	172.31.0.2#53

Non-authoritative answer:
Name:	ip-172-31-1-209.us-west-2.compute.internal
Address: 172.31.1.209

[root@ip-172-31-1-209 sbin]# nslookup 172.31.1.209
Server:		172.31.0.2
Address:	172.31.0.2#53

Non-authoritative answer:
209.1.31.172.in-addr.arpa	name = ip-172-31-1-209.us-west-2.compute.internal.

Authoritative answers can be found from:

[root@ip-172-31-1-209 sbin]# 

7)

Verifying nscd services

[root@ip-172-31-1-209 sbin]# systemctl status nscd > /dev/null; echo $?
0
[root@ip-172-31-1-209 sbin]# ./cluster_fork 'systemctl status nscd > /dev/null; echo $?'
0
0
0
0
[root@ip-172-31-1-209 sbin]#


8)

Verifying ntpd service
=================

[root@ip-172-31-1-209 sbin]# systemctl status ntpd > /dev/null; echo $?
0
[root@ip-172-31-1-209 sbin]# ./cluster_fork 'systemctl status ntpd > /dev/null; echo $?'
0
0
0
0
[root@ip-172-31-1-209 sbin]# 


Mysql server replication Status
===============================

mysql> 
mysql> show slave status \G
*************************** 1. row ***************************
               Slave_IO_State: Waiting for master to send event
                  Master_Host: ip-172-31-1-209.us-west-2.compute.internal
                  Master_User: root
                  Master_Port: 3306
                Connect_Retry: 60
              Master_Log_File: ip-172-31-1-209-bin.000001
          Read_Master_Log_Pos: 154
               Relay_Log_File: ip-172-31-1-208-relay-bin.000002
                Relay_Log_Pos: 330
        Relay_Master_Log_File: ip-172-31-1-209-bin.000001
             Slave_IO_Running: Yes
            Slave_SQL_Running: Yes
              Replicate_Do_DB: 
          Replicate_Ignore_DB: 
           Replicate_Do_Table: 
       Replicate_Ignore_Table: 
      Replicate_Wild_Do_Table: 
  Replicate_Wild_Ignore_Table: 
                   Last_Errno: 0
                   Last_Error: 
                 Skip_Counter: 0
          Exec_Master_Log_Pos: 154
              Relay_Log_Space: 547
              Until_Condition: None
               Until_Log_File: 
                Until_Log_Pos: 0
           Master_SSL_Allowed: No
           Master_SSL_CA_File: 
           Master_SSL_CA_Path: 
              Master_SSL_Cert: 
            Master_SSL_Cipher: 
               Master_SSL_Key: 
        Seconds_Behind_Master: 0
Master_SSL_Verify_Server_Cert: No
                Last_IO_Errno: 0
                Last_IO_Error: 
               Last_SQL_Errno: 0
               Last_SQL_Error: 
  Replicate_Ignore_Server_Ids: 
             Master_Server_Id: 1
                  Master_UUID: 0af9989a-bad2-11e6-a314-0a726d2d2bab
             Master_Info_File: /var/lib/mysql/master.info
                    SQL_Delay: 0
          SQL_Remaining_Delay: NULL
      Slave_SQL_Running_State: Slave has read all relay log; waiting for more updates
           Master_Retry_Count: 86400
                  Master_Bind: 
      Last_IO_Error_Timestamp: 
     Last_SQL_Error_Timestamp: 
               Master_SSL_Crl: 
           Master_SSL_Crlpath: 
           Retrieved_Gtid_Set: 
            Executed_Gtid_Set: 
                Auto_Position: 0
         Replicate_Rewrite_DB: 
                 Channel_Name: 
           Master_TLS_Version: 
1 row in set (0.00 sec)

mysql> 



